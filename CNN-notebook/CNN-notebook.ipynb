{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Classification using Convolutional Neural Networks\n",
    "---\n",
    "<br>\n",
    "\n",
    "### Name and ID:\n",
    "Yoav Gal: -\n",
    "<br>\n",
    "Guy Houri: -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "This notebook explores different approaches to car classification using end to end Convolutional Neural Networks (CNNs). The notebook is structured as follows:\n",
    "\n",
    "1. **Installations** - Setting up the required libraries and dependencies\n",
    "2. **Utilities** - Helper functions for data processing, visualization,model evaluation, and model training.\n",
    "3. **Data Preparation** - Loading and preprocessing the Stanford Cars dataset (agmentation and manipulation for qiuck training)\n",
    "4. **Experiment 1** -\n",
    "5. **Experiment 2** -\n",
    "6. **Experiment 3** -\n",
    "7. **Save Model** - Saving the best performing model for future use\n",
    "8. **Test envitoment** - A small test envitoment to try out our best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations\n",
    "This section contains all the necessary package installations required for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.63 s (started: 2025-03-06 12:06:51 +02:00)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%pip install scipy matplotlib pillow numpy pandas tqdm torch torchvision scikit-learn gdown kagglehub openpyxl tk ipython-autotime albumentations\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Yp2acaCWG92n7_nfJjP-8WF8GE0BeVI6\n",
      "To: /Users/yoavgal/code/car-classification/CNN-notebook/stanford_cars.xlsx\n",
      "100%|████████████████████████████████████████| 686k/686k [00:00<00:00, 2.55MB/s]\n",
      "time: 5.16 s (started: 2025-03-06 08:09:02 +02:00)\n"
     ]
    }
   ],
   "source": [
    "!gdown 1Yp2acaCWG92n7_nfJjP-8WF8GE0BeVI6 # stanford_cars.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jessicali9530/stanford-cars-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.82G/1.82G [01:09<00:00, 28.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/yoavgal/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 15s (started: 2025-03-06 08:37:04 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"jessicali9530/stanford-cars-dataset\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 910 ms (started: 2025-03-06 08:09:13 +02:00)\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./content\n",
    "!mkdir ./content/images/\n",
    "!mkdir ./content/images/test\n",
    "!mkdir ./content/images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.82 s (started: 2025-03-06 08:39:21 +02:00)\n"
     ]
    }
   ],
   "source": [
    "!mv /Users/yoavgal/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2/cars_test/cars_test/* ./content/images/test\n",
    "!mv /Users/yoavgal/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2/cars_train/cars_train/* ./content/images/train\n",
    "!mv /Users/yoavgal/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2/cars_annos.mat ./content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial (one time) data preperation\n",
    "\n",
    "In this section we will:\n",
    "\n",
    "- Modify the dataset from 50/50 split to 70/30 split.\n",
    "- Create and save images tensors once so that it can be used later without a lot of processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.66 ms (started: 2025-03-06 18:50:14 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset to 70/30\n",
    "\n",
    "The inital data set contains 8000 images for 196 classes , thats only about 40 (assuming no validation set) images per class, this number is very small when tring to classify beween 196 classes, to help with that we will take some of the test data (with the class proprtion) and add it to the test to get an 11000 images (55 per class). \n",
    "\n",
    "*later on we would agument the images as well to have more \"uniqe\" traning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Yp2acaCWG92n7_nfJjP-8WF8GE0BeVI6\n",
      "To: /Users/yoavgal/code/car-classification/CNN-notebook/stanford_cars.xlsx\n",
      "100%|████████████████████████████████████████| 686k/686k [00:00<00:00, 2.61MB/s]\n",
      "time: 4.67 s (started: 2025-03-06 09:34:49 +02:00)\n"
     ]
    }
   ],
   "source": [
    "!gdown 1Yp2acaCWG92n7_nfJjP-8WF8GE0BeVI6 # original stanford_cars.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train set: 8144 samples\n",
      "Original test set: 8041 samples\n",
      "Moved from test to train: 3216 samples\n",
      "New train set: 11360 samples\n",
      "New test set: 4825 samples\n",
      "time: 874 ms (started: 2025-03-06 09:34:54 +02:00)\n"
     ]
    }
   ],
   "source": [
    "excel_path = 'stanford_cars.xlsx'\n",
    "train_df = pd.read_excel(excel_path, sheet_name='train')\n",
    "test_df = pd.read_excel(excel_path, sheet_name='test')\n",
    "\n",
    "train_df['image'] = 'train/' + train_df['image']\n",
    "test_df['image'] = 'test/' + test_df['image']\n",
    "\n",
    "# Get class distribution in test set\n",
    "test_class_counts = test_df['class'].value_counts(normalize=True)\n",
    "\n",
    "# Select 40% of test data to move to train, stratified by class\n",
    "test_to_move, test_to_keep = train_test_split(\n",
    "    test_df, \n",
    "    test_size=0.6, \n",
    "    stratify=test_df['class'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Verify the class distribution is maintained\n",
    "moved_class_counts = test_to_move['class'].value_counts(normalize=True)\n",
    "kept_class_counts = test_to_keep['class'].value_counts(normalize=True)\n",
    "\n",
    "\n",
    "new_train_df = pd.concat([train_df, test_to_move], ignore_index=True)\n",
    "new_test_df = test_to_keep.copy()\n",
    "\n",
    "# Also save as CSV for easier handling\n",
    "new_train_df.to_csv('stanford_cars_train.csv', index=False)\n",
    "new_test_df.to_csv('stanford_cars_test.csv', index=False)\n",
    "\n",
    "print(f\"Original train set: {len(train_df)} samples\")\n",
    "print(f\"Original test set: {len(test_df)} samples\")\n",
    "print(f\"Moved from test to train: {len(test_to_move)} samples\")\n",
    "print(f\"New train set: {len(new_train_df)} samples\")\n",
    "print(f\"New test set: {len(new_test_df)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and agumantaition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize:\n",
    "Tensors are saved in a grayscale format:\n",
    " - saves memory (1 channel instead of 3 for RGB).\n",
    " - removes partly \"color\" noise - all cars can theoretically come in all colors, so color won't have anything to do with the car type.\n",
    "\n",
    "We save the tensors in a 160X160 (25k) resolution, which is half the size of 224X224 (50k) for faster training.\n",
    "\n",
    "By taking these steps, we made our training time to process 1 image 6 (2X3) times faster, for a bit less quality for the images, a great trade-off where compute is our main bottleneck.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 303 μs (started: 2025-03-06 19:02:43 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def grayscale_normalization(output_size=(160, 160)):\n",
    "    return transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize(output_size,interpolation=transforms.InterpolationMode.LANCZOS),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agumantaition\n",
    "Do to the small size of the dataset we decided to augment some data so the we would have a bigger traning set and try to generalize better.\n",
    "\n",
    "| Augmentation Type | Probability | Parameters/Effects |\n",
    "|-------------------|-------------|-------------------|\n",
    "| HorizontalFlip | 50% | Mirrors image horizontally |\n",
    "| RandomAffine | 50% | Rotation: ±15°<br>Translation: ±10%<br>Scale: 0.9-1.1x |\n",
    "| ColorJitter | 33% | Brightness: ±20%<br>Contrast: ±20% |\n",
    "| GaussianBlur | 20% | Kernel size: 3x7 pixels |\n",
    "\n",
    "![example](https://miro.medium.com/max/1400/0*0Je9h2iT9m7ribFJ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 778 μs (started: 2025-03-06 19:26:58 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def agumantaitionCreator(output_size=(160, 160)):\n",
    "    return transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1))\n",
    "        ], p=0.5),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2)\n",
    "        ], p=0.33),\n",
    "        transforms.RandomApply([\n",
    "            transforms.GaussianBlur(kernel_size=(3, 7))\n",
    "        ], p=0.2),\n",
    "        transforms.Resize(output_size,interpolation=transforms.InterpolationMode.LANCZOS),\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.71 ms (started: 2025-03-06 19:46:45 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def csv_to_tensors(csv_path, img_dir,output_size=(160, 160)): \n",
    "    df = pd.read_csv(csv_path)\n",
    "    transform = grayscale_normalization(output_size=output_size)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_path = os.path.join(img_dir, row['image'])\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img_tensor = transform(img)\n",
    "            \n",
    "            images.append(img_tensor)\n",
    "            labels.append(row['class'] - 1)  # 0-based indexing\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    images_tensor = torch.stack(images)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    \n",
    "    print(f\"Images tensor shape: {images_tensor.shape} Image tensors labels shape: {labels_tensor.shape}\" )\n",
    "    return images_tensor, labels_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 935 μs (started: 2025-03-06 19:28:32 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def csv_to_augmented_tensors(csv_path, img_dir, aug_ratio=3, output_size=(160, 160)):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    transform = grayscale_normalization(output_size=output_size)\n",
    "    aug_transform = agumantaitionCreator(output_size=output_size)\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing original images\"):\n",
    "        img_path = os.path.join(img_dir, row['image'])\n",
    "        try:\n",
    "            # Original image\n",
    "            img = Image.open(img_path)\n",
    "            img_tensor = transform(img)\n",
    "            images.append(img_tensor)\n",
    "            labels.append(row['class'] - 1)\n",
    "            \n",
    "            # Augmented versions\n",
    "            for _ in range(aug_ratio):\n",
    "                og_img = Image.open(img_path)\n",
    "                augmented_tensor = aug_transform(og_img)\n",
    "                images.append(augmented_tensor)\n",
    "                labels.append(row['class'] - 1)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    images_tensor = torch.stack(images)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    print(f\"Final dataset size - Images: {images_tensor.shape}, Labels: {labels_tensor.shape}\")\n",
    "    return images_tensor, labels_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 541 μs (started: 2025-03-06 19:47:20 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def save_tensors_zip(tensors, output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    images_tensor, labels_tensor = tensors\n",
    "    torch.save(images_tensor, os.path.join(output_path, 'images.pt'))\n",
    "    torch.save(labels_tensor, os.path.join(output_path, 'labels.pt'))\n",
    "    \n",
    "    test = shutil.make_archive(output_path, 'zip', output_path)\n",
    "    print(f\"tensors saverd to {test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.2 ms (started: 2025-03-06 19:47:22 +02:00)\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "train_tensors = csv_to_augmented_tensors(\n",
    "    'stanford_cars_train.csv',\n",
    "    './content/images',\n",
    "    aug_ratio=3,\n",
    ")\n",
    "save_tensors_zip(train_tensors, './content/train_tensors')\n",
    "\n",
    "test_tensors = csv_to_tensors(\n",
    "    'stanford_cars_test.csv',\n",
    "    './content/images',\n",
    "    output_size=(160, 160)\n",
    ")\n",
    "save_tensors_zip(test_tensors, './content/test_tensors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "Helper functions for:\n",
    "- Imports for context\n",
    "- Data loading and preprocessing\n",
    "- Visualization of images and results\n",
    "- Model evaluation metrics\n",
    "- Training and validation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.1 ms (started: 2025-03-06 21:33:22 +02:00)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gc\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List, Tuple, Callable, Union\n",
    "import pickle\n",
    "import random\n",
    "import tempfile\n",
    "import zipfile\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.multiprocessing as mp\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score, silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from torch.utils.data import WeightedRandomSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the tensors (update to gdown first in colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 513 μs (started: 2025-03-06 19:50:44 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def load_tensors_from_zip(zip_path):\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "            \n",
    "        images = torch.load(os.path.join(temp_dir, 'images.pt'),map_location=\"cpu\")\n",
    "        labels = torch.load(os.path.join(temp_dir, 'labels.pt'),map_location=\"cpu\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Loaded Tensors from: {os.path.basename(zip_path)}\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Images Shape: {images.shape}\")\n",
    "        print(f\"Labels Shape: {labels.shape}\")\n",
    "        print(f\"Number of Classes: {len(torch.unique(labels))}\")\n",
    "        print(f\"Memory Usage: {images.element_size() * images.nelement() / 1024 / 1024:.2f} MB\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.41 ms (started: 2025-03-06 22:44:20 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def save_best_model(model: nn.Module, model_filename: str) -> None:\n",
    "  # Create a directory for saving models if it doesn't exist\n",
    "  save_dir = os.path.join(os.getcwd(), \"./saved_models\")\n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "  \n",
    "  # Save the model locally\n",
    "  save_path = os.path.join(save_dir, model_filename)\n",
    "  torch.save(model.state_dict(), save_path)\n",
    "  print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 846 μs (started: 2025-03-06 19:52:03 +02:00)\n"
     ]
    }
   ],
   "source": [
    "# CAN BE REMOVED!\n",
    "def display_augmented_tensors(images, indices, transform, num_augmentations=3, figsize=(15, 5)):\n",
    "    \"\"\"\n",
    "    Display original tensor images and their augmented versions.\n",
    "    \n",
    "    Args:\n",
    "        images: Tensor of shape [N, C, H, W]\n",
    "        indices: List of indices to display\n",
    "        transform: Albumentations transform pipeline\n",
    "        num_augmentations: Number of augmented versions to show for each image\n",
    "        figsize: Size of the figure (width, height)\n",
    "    \"\"\"\n",
    "    num_images = len(indices)\n",
    "    fig, axes = plt.subplots(num_images, num_augmentations + 1, figsize=figsize)\n",
    "    \n",
    "    if num_images == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for row, idx in enumerate(indices):\n",
    "        # Get original image and convert to numpy\n",
    "        original_image = images[idx].squeeze().numpy()\n",
    "        axes[row, 0].imshow(original_image, cmap='gray')\n",
    "        axes[row, 0].set_title('Original')\n",
    "        axes[row, 0].axis('off')\n",
    "        \n",
    "        # Get augmented versions\n",
    "        for col in range(num_augmentations):\n",
    "            # Apply transform multiple times\n",
    "            augmented = transform(image=original_image)['image']\n",
    "            if isinstance(augmented, torch.Tensor):\n",
    "                augmented = augmented.squeeze().numpy()\n",
    "            \n",
    "            axes[row, col + 1].imshow(augmented, cmap='gray')\n",
    "            axes[row, col + 1].set_title(f'Augmented {col + 1}')\n",
    "            axes[row, col + 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.11 ms (started: 2025-03-06 19:51:59 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def validate(model: nn.Module, val_loader: DataLoader, device: torch.device, criterion: nn.Module) -> Tuple[float, float]:\n",
    "  \"\"\"\n",
    "    Returns:\n",
    "        Tuple[float, float]: A tuple containing the validation accuracy and average loss.\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  running_loss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "        for images, labels in val_loader:  \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = 100 * correct / total\n",
    "  avg_loss = running_loss / len(val_loader)\n",
    "\n",
    "  return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 663 μs (started: 2025-03-06 19:51:57 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def visualize_results(train_losses: List[float], val_losses: List[float], train_accuracies: List[float], val_accuracies: List[float]) -> None:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        train_losses (List[float]): List of training loss values for each epoch.\n",
    "        val_losses (List[float]): List of validation loss values for each epoch.\n",
    "        train_accuracies (List[float]): List of training accuracy values for each epoch.\n",
    "        val_accuracies (List[float]): List of validation accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)  # Plot for Loss\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title('Training vs. Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)  # Plot for Accuracy\n",
    "    plt.plot(train_accuracies, label='Train')\n",
    "    plt.plot(val_accuracies, label='Validation')\n",
    "    plt.title('Training vs. Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 630 μs (started: 2025-03-06 19:51:57 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def generate_classification_report(model: nn.Module, data_loader: DataLoader, device: torch.device) -> None:\n",
    "    y_true: List[int] = []\n",
    "    y_pred: List[int] = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1e+03 ms (started: 2025-03-06 20:39:42 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def training_loop(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    epochs: int,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n",
    "    metric_fn: Optional[Callable[[float, float], float]] = None,\n",
    "    is_clip: bool = False,\n",
    "    clip_value: float = 1.0,\n",
    "    is_l1: bool = False,\n",
    "    none_blocking: bool = False,\n",
    "    ) -> Tuple[List[float], List[float], List[float], List[float]]:\n",
    "\n",
    "    # Lists to store training and validation metrics\n",
    "    train_losses = [0.0] * epochs\n",
    "    val_losses = [0.0] * epochs\n",
    "    train_accuracies = [0.0] * epochs\n",
    "    val_accuracies = [0.0] * epochs\n",
    "\n",
    "    clip_fn = torch.nn.utils.clip_grad_norm_ if is_clip else None\n",
    "\n",
    "    # Training and validation loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", leave=False) \n",
    "\n",
    "        for images, labels in train_loop:\n",
    "            images, labels = images.to(device, non_blocking=none_blocking), labels.to(device, non_blocking=none_blocking)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if is_l1:\n",
    "              l1_loss = model.calculate_l1_loss()\n",
    "              total_loss = loss + l1_loss\n",
    "              total_loss.backward()\n",
    "            else:\n",
    "              loss.backward()\n",
    "\n",
    "            if clip_fn:\n",
    "                clip_fn(model.parameters(), clip_value)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "\n",
    "        # Store training metrics\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation\n",
    "        val_accuracy, val_loss = validate(model, val_loader, device, criterion)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Step the scheduler with the metric if scheduler and metric_fn are provided\n",
    "        if scheduler and metric_fn:\n",
    "            metric = metric_fn(val_accuracy, val_loss)\n",
    "            scheduler.step(metric)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "In this section, we will:\n",
    "- Load the Stanford Cars dataset\n",
    "- Explore the dataset characteristics\n",
    "- Preprocess the images (resizing, normalization, etc.)\n",
    "- Split the data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Loaded Tensors from: train_tensors.zip\n",
      "==================================================\n",
      "Images Shape: torch.Size([45440, 1, 160, 160])\n",
      "Labels Shape: torch.Size([45440])\n",
      "Number of Classes: 196\n",
      "Memory Usage: 4437.50 MB\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Loaded Tensors from: test_tensors.zip\n",
      "==================================================\n",
      "Images Shape: torch.Size([4825, 1, 160, 160])\n",
      "Labels Shape: torch.Size([4825])\n",
      "Number of Classes: 196\n",
      "Memory Usage: 471.19 MB\n",
      "==================================================\n",
      "\n",
      "time: 11.6 s (started: 2025-03-06 20:05:42 +02:00)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_images, train_labels = load_tensors_from_zip('./content/train_tensors.zip')\n",
    "test_images, test_labels = load_tensors_from_zip('./content/test_tensors.zip')\n",
    "batch_size = 64\n",
    "num_workers=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CarDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.99 ms (started: 2025-03-06 21:35:19 +02:00)\n"
     ]
    }
   ],
   "source": [
    "class CarDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # if self.transform:\n",
    "        #    if torch.is_tensor(image):\n",
    "        #       image = image.squeeze().numpy()\n",
    "        #    transformed = self.transform(image=image)\n",
    "        #    image = transformed['image'] \n",
    "     \n",
    "        # if not torch.is_tensor(image):\n",
    "        #     image = torch.from_numpy(image)\n",
    "        \n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 426 μs (started: 2025-03-06 20:12:41 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def create_sampler_with_weighted_sampler(labels):\n",
    "    class_counts = torch.bincount(labels)\n",
    "    weights = 1.0 / class_counts.float()\n",
    "    sample_weights = weights[labels]\n",
    "\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(labels),\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 811 μs (started: 2025-03-06 21:35:48 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def create_train_val_loaders(train_images, train_labels, val_size=0.15, batch_size=batch_size, num_workers=num_workers, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    dataset_size = len(train_labels)\n",
    "    val_length = int(dataset_size * val_size)\n",
    "    train_length = dataset_size - val_length\n",
    "    \n",
    "    full_train_dataset = CarDataset(\n",
    "        train_images, \n",
    "        train_labels,\n",
    "    )\n",
    "    \n",
    "    train_subset, val_subset = random_split(\n",
    "        full_train_dataset, \n",
    "        [train_length, val_length],\n",
    "        generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "    \n",
    "    # train_subset.dataset.transform = train_transform \n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        # sampler=create_sampler_with_weighted_sampler(train_subset.dataset.labels),\n",
    "        # num_workers=num_workers,\n",
    "        # persistent_workers=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        # num_workers=num_workers,\n",
    "        # persistent_workers=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Data Split Information\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total dataset size: {dataset_size}\")\n",
    "    print(f\"Training set size: {train_length}\")\n",
    "    print(f\"Validation set size: {val_length}\")\n",
    "    print(f\"Number of training batches: {len(train_loader)}\")\n",
    "    print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Data Split Information\n",
      "==================================================\n",
      "Total dataset size: 45440\n",
      "Training set size: 38624\n",
      "Validation set size: 6816\n",
      "Number of training batches: 302\n",
      "Number of validation batches: 54\n",
      "==================================================\n",
      "\n",
      "time: 6.33 ms (started: 2025-03-06 21:35:53 +02:00)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = create_train_val_loaders(train_images, train_labels, batch_size=128)\n",
    "\n",
    "test_dataset = CarDataset(test_images, test_labels)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Basic CNN Architecture\n",
    "In this experiment, we will:\n",
    "- Design a basic CNN architecture from scratch\n",
    "- Train the model on the prepared dataset\n",
    "- Evaluate the model performance\n",
    "- Analyze the results and identify areas for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grayscale_CNN_exp_1_GAP(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc3): Linear(in_features=64, out_features=196, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62.8 ms (started: 2025-03-06 22:27:04 +02:00)\n"
     ]
    }
   ],
   "source": [
    "class Grayscale_CNN_exp_1_GAP(nn.Module):\n",
    "    def __init__(self, num_classes=196):\n",
    "        super(Grayscale_CNN_exp_1_GAP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding='same')\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Global Average Pooling Layer\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))  # Output size of (1, 1)\n",
    "\n",
    "        # Final classification layer\n",
    "        self.fc3 = nn.Linear(64, num_classes)  # Input is now just the number of channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Apply Global Average Pooling\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten to [batch_size, 64]\n",
    "\n",
    "        # Classification\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "# Create an instance of the model\n",
    "grayscale_cnn_exp1_model = Grayscale_CNN_exp_1_GAP()\n",
    "grayscale_cnn_exp1_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/35], Loss: 1.3803, Validation Loss: 2.4361, Validation Accuracy: 43.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/35], Loss: 1.3426, Validation Loss: 2.5514, Validation Accuracy: 42.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/35], Loss: 1.3302, Validation Loss: 2.9757, Validation Accuracy: 36.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/35], Loss: 1.3394, Validation Loss: 2.5236, Validation Accuracy: 41.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/35], Loss: 1.3114, Validation Loss: 2.5038, Validation Accuracy: 41.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/35], Loss: 1.3155, Validation Loss: 2.3261, Validation Accuracy: 44.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/35], Loss: 1.2979, Validation Loss: 2.6312, Validation Accuracy: 41.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/35], Loss: 1.2945, Validation Loss: 2.9360, Validation Accuracy: 37.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/35], Loss: 1.2752, Validation Loss: 2.3824, Validation Accuracy: 45.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/35], Loss: 1.2766, Validation Loss: 2.6945, Validation Accuracy: 39.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/35], Loss: 1.2736, Validation Loss: 2.4079, Validation Accuracy: 44.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/35], Loss: 1.2692, Validation Loss: 2.6016, Validation Accuracy: 42.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/35], Loss: 1.2486, Validation Loss: 2.4893, Validation Accuracy: 43.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/35], Loss: 1.2437, Validation Loss: 2.3465, Validation Accuracy: 45.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/35], Loss: 1.2363, Validation Loss: 2.3515, Validation Accuracy: 44.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/35], Loss: 1.2217, Validation Loss: 2.7306, Validation Accuracy: 41.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/35], Loss: 1.2277, Validation Loss: 2.3368, Validation Accuracy: 46.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/35], Loss: 1.2205, Validation Loss: 2.5216, Validation Accuracy: 44.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/35], Loss: 1.2108, Validation Loss: 2.8187, Validation Accuracy: 39.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/35], Loss: 1.2058, Validation Loss: 2.4100, Validation Accuracy: 46.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/35], Loss: 1.1917, Validation Loss: 2.3209, Validation Accuracy: 44.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/35], Loss: 1.1902, Validation Loss: 2.2999, Validation Accuracy: 46.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/35], Loss: 1.1731, Validation Loss: 2.3646, Validation Accuracy: 46.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/35], Loss: 1.1754, Validation Loss: 2.5742, Validation Accuracy: 45.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/35], Loss: 1.1760, Validation Loss: 3.0525, Validation Accuracy: 38.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/35], Loss: 1.1637, Validation Loss: 2.5752, Validation Accuracy: 44.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/35], Loss: 1.1649, Validation Loss: 2.2909, Validation Accuracy: 46.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/35], Loss: 1.1568, Validation Loss: 2.3893, Validation Accuracy: 46.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/35], Loss: 1.1473, Validation Loss: 2.5138, Validation Accuracy: 45.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/35], Loss: 1.1427, Validation Loss: 2.6109, Validation Accuracy: 41.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/35], Loss: 1.1278, Validation Loss: 2.8933, Validation Accuracy: 41.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/35], Loss: 1.1401, Validation Loss: 2.2924, Validation Accuracy: 46.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/35], Loss: 1.1228, Validation Loss: 2.4319, Validation Accuracy: 46.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/35], Loss: 1.1196, Validation Loss: 2.4295, Validation Accuracy: 45.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/35], Loss: 1.1028, Validation Loss: 2.4707, Validation Accuracy: 44.57%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3132\n",
      "F1 Score: 0.3132\n",
      "Precision: 0.3669\n",
      "Recall: 0.3132\n",
      "time: 9min 34s (started: 2025-03-06 22:59:32 +02:00)\n"
     ]
    }
   ],
   "source": [
    "epochs=100 \n",
    "lr=0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(grayscale_cnn_exp1_model.parameters(), lr)\n",
    "\n",
    "train_loss, val_loss, train_acc, val_acc = training_loop(\n",
    "    grayscale_cnn_exp1_model, optimizer, criterion, epochs, train_loader, val_loader, is_clip=True ,none_blocking=True)\n",
    "\n",
    "visualize_results(train_loss, val_loss, train_acc, val_acc)\n",
    "generate_classification_report(grayscale_cnn_exp1_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Transfer Learning Approach\n",
    "In this experiment, we will:\n",
    "- Utilize pre-trained models (e.g., ResNet, VGG, EfficientNet)\n",
    "- Fine-tune the models for our car classification task\n",
    "- Compare the performance with the basic CNN architecture\n",
    "- Analyze the benefits and limitations of transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: Advanced Techniques\n",
    "In this experiment, we will:\n",
    "- Implement advanced techniques such as data augmentation\n",
    "- Explore different optimization strategies\n",
    "- Experiment with ensemble methods\n",
    "- Analyze the impact of these techniques on model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model\n",
    "In this section, we will:\n",
    "- Save the best performing model\n",
    "- Document the model architecture and hyperparameters\n",
    "- Prepare the model for deployment or future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /Users/yoavgal/code/car-classification/CNN-notebook/./saved_models/Grayscale_CNN_exp_1_GAP\n",
      "time: 30.4 ms (started: 2025-03-06 23:11:06 +02:00)\n"
     ]
    }
   ],
   "source": [
    "model_filename = \"Grayscale_CNN_exp_1_GAP\"\n",
    "save_best_model(grayscale_cnn_exp1_model,model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model\n",
    "In this section, we will:\n",
    "- Evaluate the final model on the test dataset\n",
    "- Generate classification reports and confusion matrices\n",
    "- Visualize the model's predictions on sample images\n",
    "- Discuss the strengths and weaknesses of our approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
