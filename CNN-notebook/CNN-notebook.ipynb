{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Classification using Convolutional Neural Networks\n",
    "---\n",
    "<br>\n",
    "\n",
    "### Name and ID:\n",
    "Yoav Gal: -\n",
    "<br>\n",
    "Guy Houri: -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "This notebook explores different approaches to car classification using end to end Convolutional Neural Networks (CNNs). The notebook is structured as follows:\n",
    "\n",
    "1. **Installations** - Setting up the required libraries and dependencies\n",
    "2. **Utilities** - Helper functions for data processing, visualization,model evaluation, and model training.\n",
    "3. **Data Preparation** - Loading and preprocessing the Stanford Cars dataset (agmentation and manipulation for qiuck training)\n",
    "4. **Experiment 1** -\n",
    "5. **Experiment 2** -\n",
    "6. **Experiment 3** -\n",
    "7. **Save Model** - Saving the best performing model for future use\n",
    "8. **Test envitoment** - A small test envitoment to try out our best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installations\n",
    "This section contains all the necessary package installations required for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.63 s (started: 2025-03-06 12:06:51 +02:00)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "%pip install scipy matplotlib pillow numpy pandas tqdm torch torchvision scikit-learn gdown kagglehub openpyxl tk ipython-autotime albumentations\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Yp2acaCWG92n7_nfJjP-8WF8GE0BeVI6\n",
      "To: /Users/yoavgal/code/car-classification/CNN-notebook/stanford_cars.xlsx\n",
      "100%|████████████████████████████████████████| 686k/686k [00:00<00:00, 2.55MB/s]\n",
      "time: 5.16 s (started: 2025-03-06 08:09:02 +02:00)\n"
     ]
    }
   ],
   "source": [
    "!gdown 1Yp2acaCWG92n7_nfJjP-8WF8GE0BeVI6 # stanford_cars.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jessicali9530/stanford-cars-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.82G/1.82G [01:09<00:00, 28.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/yoavgal/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 15s (started: 2025-03-06 08:37:04 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"jessicali9530/stanford-cars-dataset\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 910 ms (started: 2025-03-06 08:09:13 +02:00)\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./content\n",
    "!mkdir ./content/images/\n",
    "!mkdir ./content/images/test\n",
    "!mkdir ./content/images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.82 s (started: 2025-03-06 08:39:21 +02:00)\n"
     ]
    }
   ],
   "source": [
    "!mv /Users/yoavgal/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2/cars_test/cars_test/* ./content/images/test\n",
    "!mv /Users/yoavgal/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2/cars_train/cars_train/* ./content/images/train\n",
    "!mv /Users/yoavgal/.cache/kagglehub/datasets/jessicali9530/stanford-cars-dataset/versions/2/cars_annos.mat ./content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial (one time) data preperation\n",
    "\n",
    "In this section we will:\n",
    "\n",
    "- Modify the dataset from 50/50 split to 70/30 split.\n",
    "- Create and save images tensors once so that it can be used later without a lot of processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.66 ms (started: 2025-03-06 18:50:14 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset to 70/30\n",
    "\n",
    "The inital data set contains 8000 images for 196 classes , thats only about 40 (assuming no validation set) images per class, this number is very small when tring to classify beween 196 classes, to help with that we will take some of the test data (with the class proprtion) and add it to the test to get an 11000 images (55 per class). \n",
    "\n",
    "*later on we would agument the images as well to have more \"uniqe\" traning data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Yp2acaCWG92n7_nfJjP-8WF8GE0BeVI6\n",
      "To: /Users/yoavgal/code/car-classification/CNN-notebook/stanford_cars.xlsx\n",
      "100%|████████████████████████████████████████| 686k/686k [00:00<00:00, 2.61MB/s]\n",
      "time: 4.67 s (started: 2025-03-06 09:34:49 +02:00)\n"
     ]
    }
   ],
   "source": [
    "!gdown 1Yp2acaCWG92n7_nfJjP-8WF8GE0BeVI6 # original stanford_cars.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train set: 8144 samples\n",
      "Original test set: 8041 samples\n",
      "Moved from test to train: 3216 samples\n",
      "New train set: 11360 samples\n",
      "New test set: 4825 samples\n",
      "time: 874 ms (started: 2025-03-06 09:34:54 +02:00)\n"
     ]
    }
   ],
   "source": [
    "excel_path = 'stanford_cars.xlsx'\n",
    "train_df = pd.read_excel(excel_path, sheet_name='train')\n",
    "test_df = pd.read_excel(excel_path, sheet_name='test')\n",
    "\n",
    "train_df['image'] = 'train/' + train_df['image']\n",
    "test_df['image'] = 'test/' + test_df['image']\n",
    "\n",
    "# Get class distribution in test set\n",
    "test_class_counts = test_df['class'].value_counts(normalize=True)\n",
    "\n",
    "# Select 40% of test data to move to train, stratified by class\n",
    "test_to_move, test_to_keep = train_test_split(\n",
    "    test_df, \n",
    "    test_size=0.6, \n",
    "    stratify=test_df['class'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Verify the class distribution is maintained\n",
    "moved_class_counts = test_to_move['class'].value_counts(normalize=True)\n",
    "kept_class_counts = test_to_keep['class'].value_counts(normalize=True)\n",
    "\n",
    "\n",
    "new_train_df = pd.concat([train_df, test_to_move], ignore_index=True)\n",
    "new_test_df = test_to_keep.copy()\n",
    "\n",
    "# Also save as CSV for easier handling\n",
    "new_train_df.to_csv('stanford_cars_train.csv', index=False)\n",
    "new_test_df.to_csv('stanford_cars_test.csv', index=False)\n",
    "\n",
    "print(f\"Original train set: {len(train_df)} samples\")\n",
    "print(f\"Original test set: {len(test_df)} samples\")\n",
    "print(f\"Moved from test to train: {len(test_to_move)} samples\")\n",
    "print(f\"New train set: {len(new_train_df)} samples\")\n",
    "print(f\"New test set: {len(new_test_df)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and agumantaition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize:\n",
    "Tensors are saved in a grayscale format:\n",
    " - saves memory (1 channel instead of 3 for RGB).\n",
    " - removes partly \"color\" noise - all cars can theoretically come in all colors, so color won't have anything to do with the car type.\n",
    "\n",
    "We save the tensors in a 160X160 (25k) resolution, which is half the size of 224X224 (50k) for faster training.\n",
    "\n",
    "By taking these steps, we made our training time to process 1 image 6 (2X3) times faster, for a bit less quality for the images, a great trade-off where compute is our main bottleneck.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 303 μs (started: 2025-03-06 19:02:43 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def grayscale_normalization(output_size=(160, 160)):\n",
    "    return transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.Resize(output_size,interpolation=transforms.InterpolationMode.LANCZOS),\n",
    "        transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agumantaition\n",
    "Do to the small size of the dataset we decided to augment some data so the we would have a bigger traning set and try to generalize better.\n",
    "\n",
    "| Augmentation Type | Probability | Parameters/Effects |\n",
    "|-------------------|-------------|-------------------|\n",
    "| HorizontalFlip | 50% | Mirrors image horizontally |\n",
    "| RandomAffine | 50% | Rotation: ±15°<br>Translation: ±10%<br>Scale: 0.9-1.1x |\n",
    "| ColorJitter | 33% | Brightness: ±20%<br>Contrast: ±20% |\n",
    "| GaussianBlur | 20% | Kernel size: 3x7 pixels |\n",
    "\n",
    "![example](https://miro.medium.com/max/1400/0*0Je9h2iT9m7ribFJ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 778 μs (started: 2025-03-06 19:26:58 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def agumantaitionCreator(output_size=(160, 160)):\n",
    "    return transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1))\n",
    "        ], p=0.5),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2)\n",
    "        ], p=0.33),\n",
    "        transforms.RandomApply([\n",
    "            transforms.GaussianBlur(kernel_size=(3, 7))\n",
    "        ], p=0.2),\n",
    "        transforms.Resize(output_size,interpolation=transforms.InterpolationMode.LANCZOS),\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build tensors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.71 ms (started: 2025-03-06 19:46:45 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def csv_to_tensors(csv_path, img_dir,output_size=(160, 160)): \n",
    "    df = pd.read_csv(csv_path)\n",
    "    transform = grayscale_normalization(output_size=output_size)\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_path = os.path.join(img_dir, row['image'])\n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            img_tensor = transform(img)\n",
    "            \n",
    "            images.append(img_tensor)\n",
    "            labels.append(row['class'] - 1)  # 0-based indexing\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    images_tensor = torch.stack(images)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    \n",
    "    print(f\"Images tensor shape: {images_tensor.shape} Image tensors labels shape: {labels_tensor.shape}\" )\n",
    "    return images_tensor, labels_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 935 μs (started: 2025-03-06 19:28:32 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def csv_to_augmented_tensors(csv_path, img_dir, aug_ratio=3, output_size=(160, 160)):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    transform = grayscale_normalization(output_size=output_size)\n",
    "    aug_transform = agumantaitionCreator(output_size=output_size)\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing original images\"):\n",
    "        img_path = os.path.join(img_dir, row['image'])\n",
    "        try:\n",
    "            # Original image\n",
    "            img = Image.open(img_path)\n",
    "            img_tensor = transform(img)\n",
    "            images.append(img_tensor)\n",
    "            labels.append(row['class'] - 1)\n",
    "            \n",
    "            # Augmented versions\n",
    "            for _ in range(aug_ratio):\n",
    "                og_img = Image.open(img_path)\n",
    "                augmented_tensor = aug_transform(og_img)\n",
    "                images.append(augmented_tensor)\n",
    "                labels.append(row['class'] - 1)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    images_tensor = torch.stack(images)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    print(f\"Final dataset size - Images: {images_tensor.shape}, Labels: {labels_tensor.shape}\")\n",
    "    return images_tensor, labels_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 541 μs (started: 2025-03-06 19:47:20 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def save_tensors_zip(tensors, output_path):\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    images_tensor, labels_tensor = tensors\n",
    "    torch.save(images_tensor, os.path.join(output_path, 'images.pt'))\n",
    "    torch.save(labels_tensor, os.path.join(output_path, 'labels.pt'))\n",
    "    \n",
    "    test = shutil.make_archive(output_path, 'zip', output_path)\n",
    "    print(f\"tensors saverd to {test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.2 ms (started: 2025-03-06 19:47:22 +02:00)\n"
     ]
    }
   ],
   "source": [
    "%%script echo skipping\n",
    "train_tensors = csv_to_augmented_tensors(\n",
    "    'stanford_cars_train.csv',\n",
    "    './content/images',\n",
    "    aug_ratio=3,\n",
    ")\n",
    "save_tensors_zip(train_tensors, './content/train_tensors')\n",
    "\n",
    "test_tensors = csv_to_tensors(\n",
    "    'stanford_cars_test.csv',\n",
    "    './content/images',\n",
    "    output_size=(160, 160)\n",
    ")\n",
    "save_tensors_zip(test_tensors, './content/test_tensors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "Helper functions for:\n",
    "- Imports for context\n",
    "- Data loading and preprocessing\n",
    "- Visualization of images and results\n",
    "- Model evaluation metrics\n",
    "- Training and validation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.1 ms (started: 2025-03-06 21:33:22 +02:00)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gc\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List, Tuple, Callable, Union\n",
    "import pickle\n",
    "import random\n",
    "import tempfile\n",
    "import zipfile\n",
    "import albumentations as A\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.multiprocessing as mp\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score, silhouette_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from torch.utils.data import WeightedRandomSampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the tensors (update to gdown first in colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 513 μs (started: 2025-03-06 19:50:44 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def load_tensors_from_zip(zip_path):\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(temp_dir)\n",
    "            \n",
    "        images = torch.load(os.path.join(temp_dir, 'images.pt'),map_location=\"cpu\")\n",
    "        labels = torch.load(os.path.join(temp_dir, 'labels.pt'),map_location=\"cpu\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Loaded Tensors from: {os.path.basename(zip_path)}\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Images Shape: {images.shape}\")\n",
    "        print(f\"Labels Shape: {labels.shape}\")\n",
    "        print(f\"Number of Classes: {len(torch.unique(labels))}\")\n",
    "        print(f\"Memory Usage: {images.element_size() * images.nelement() / 1024 / 1024:.2f} MB\")\n",
    "        print(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "        return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.41 ms (started: 2025-03-06 22:44:20 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def save_best_model(model: nn.Module, model_filename: str) -> None:\n",
    "  # Create a directory for saving models if it doesn't exist\n",
    "  save_dir = os.path.join(os.getcwd(), \"./saved_models\")\n",
    "  os.makedirs(save_dir, exist_ok=True)\n",
    "  \n",
    "  # Save the model locally\n",
    "  save_path = os.path.join(save_dir, model_filename)\n",
    "  torch.save(model.state_dict(), save_path)\n",
    "  print(f\"Model saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 846 μs (started: 2025-03-06 19:52:03 +02:00)\n"
     ]
    }
   ],
   "source": [
    "# CAN BE REMOVED!\n",
    "def display_augmented_tensors(images, indices, transform, num_augmentations=3, figsize=(15, 5)):\n",
    "    \"\"\"\n",
    "    Display original tensor images and their augmented versions.\n",
    "    \n",
    "    Args:\n",
    "        images: Tensor of shape [N, C, H, W]\n",
    "        indices: List of indices to display\n",
    "        transform: Albumentations transform pipeline\n",
    "        num_augmentations: Number of augmented versions to show for each image\n",
    "        figsize: Size of the figure (width, height)\n",
    "    \"\"\"\n",
    "    num_images = len(indices)\n",
    "    fig, axes = plt.subplots(num_images, num_augmentations + 1, figsize=figsize)\n",
    "    \n",
    "    if num_images == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for row, idx in enumerate(indices):\n",
    "        # Get original image and convert to numpy\n",
    "        original_image = images[idx].squeeze().numpy()\n",
    "        axes[row, 0].imshow(original_image, cmap='gray')\n",
    "        axes[row, 0].set_title('Original')\n",
    "        axes[row, 0].axis('off')\n",
    "        \n",
    "        # Get augmented versions\n",
    "        for col in range(num_augmentations):\n",
    "            # Apply transform multiple times\n",
    "            augmented = transform(image=original_image)['image']\n",
    "            if isinstance(augmented, torch.Tensor):\n",
    "                augmented = augmented.squeeze().numpy()\n",
    "            \n",
    "            axes[row, col + 1].imshow(augmented, cmap='gray')\n",
    "            axes[row, col + 1].set_title(f'Augmented {col + 1}')\n",
    "            axes[row, col + 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.11 ms (started: 2025-03-06 19:51:59 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def validate(model: nn.Module, val_loader: DataLoader, device: torch.device, criterion: nn.Module) -> Tuple[float, float]:\n",
    "  \"\"\"\n",
    "    Returns:\n",
    "        Tuple[float, float]: A tuple containing the validation accuracy and average loss.\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  running_loss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "        for images, labels in val_loader:  \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy = 100 * correct / total\n",
    "  avg_loss = running_loss / len(val_loader)\n",
    "\n",
    "  return accuracy, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 663 μs (started: 2025-03-06 19:51:57 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def visualize_results(train_losses: List[float], val_losses: List[float], train_accuracies: List[float], val_accuracies: List[float]) -> None:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        train_losses (List[float]): List of training loss values for each epoch.\n",
    "        val_losses (List[float]): List of validation loss values for each epoch.\n",
    "        train_accuracies (List[float]): List of training accuracy values for each epoch.\n",
    "        val_accuracies (List[float]): List of validation accuracy values for each epoch.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)  # Plot for Loss\n",
    "    plt.plot(train_losses, label='Train')\n",
    "    plt.plot(val_losses, label='Validation')\n",
    "    plt.title('Training vs. Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)  # Plot for Accuracy\n",
    "    plt.plot(train_accuracies, label='Train')\n",
    "    plt.plot(val_accuracies, label='Validation')\n",
    "    plt.title('Training vs. Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 630 μs (started: 2025-03-06 19:51:57 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def generate_classification_report(model: nn.Module, data_loader: DataLoader, device: torch.device) -> None:\n",
    "    y_true: List[int] = []\n",
    "    y_pred: List[int] = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1e+03 ms (started: 2025-03-06 20:39:42 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def training_loop(\n",
    "    model: nn.Module,\n",
    "    optimizer: optim.Optimizer,\n",
    "    criterion: nn.Module,\n",
    "    epochs: int,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    scheduler: Optional[optim.lr_scheduler._LRScheduler] = None,\n",
    "    metric_fn: Optional[Callable[[float, float], float]] = None,\n",
    "    is_clip: bool = False,\n",
    "    clip_value: float = 1.0,\n",
    "    is_l1: bool = False,\n",
    "    none_blocking: bool = False,\n",
    "    ) -> Tuple[List[float], List[float], List[float], List[float]]:\n",
    "\n",
    "    # Lists to store training and validation metrics\n",
    "    train_losses = [0.0] * epochs\n",
    "    val_losses = [0.0] * epochs\n",
    "    train_accuracies = [0.0] * epochs\n",
    "    val_accuracies = [0.0] * epochs\n",
    "\n",
    "    clip_fn = torch.nn.utils.clip_grad_norm_ if is_clip else None\n",
    "\n",
    "    # Training and validation loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        train_loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", leave=False) \n",
    "\n",
    "        for images, labels in train_loop:\n",
    "            images, labels = images.to(device, non_blocking=none_blocking), labels.to(device, non_blocking=none_blocking)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            if is_l1:\n",
    "              l1_loss = model.calculate_l1_loss()\n",
    "              total_loss = loss + l1_loss\n",
    "              total_loss.backward()\n",
    "            else:\n",
    "              loss.backward()\n",
    "\n",
    "            if clip_fn:\n",
    "                clip_fn(model.parameters(), clip_value)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct / total\n",
    "\n",
    "        # Store training metrics\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # Validation\n",
    "        val_accuracy, val_loss = validate(model, val_loader, device, criterion)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        # Step the scheduler with the metric if scheduler and metric_fn are provided\n",
    "        if scheduler and metric_fn:\n",
    "            metric = metric_fn(val_accuracy, val_loss)\n",
    "            scheduler.step(metric)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    return train_losses, val_losses, train_accuracies, val_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "In this section, we will:\n",
    "- Load the Stanford Cars dataset\n",
    "- Explore the dataset characteristics\n",
    "- Preprocess the images (resizing, normalization, etc.)\n",
    "- Split the data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Loaded Tensors from: train_tensors.zip\n",
      "==================================================\n",
      "Images Shape: torch.Size([45440, 1, 160, 160])\n",
      "Labels Shape: torch.Size([45440])\n",
      "Number of Classes: 196\n",
      "Memory Usage: 4437.50 MB\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "Loaded Tensors from: test_tensors.zip\n",
      "==================================================\n",
      "Images Shape: torch.Size([4825, 1, 160, 160])\n",
      "Labels Shape: torch.Size([4825])\n",
      "Number of Classes: 196\n",
      "Memory Usage: 471.19 MB\n",
      "==================================================\n",
      "\n",
      "time: 11.6 s (started: 2025-03-06 20:05:42 +02:00)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_images, train_labels = load_tensors_from_zip('./content/train_tensors.zip')\n",
    "test_images, test_labels = load_tensors_from_zip('./content/test_tensors.zip')\n",
    "batch_size = 64\n",
    "num_workers=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CarDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.99 ms (started: 2025-03-06 21:35:19 +02:00)\n"
     ]
    }
   ],
   "source": [
    "class CarDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # if self.transform:\n",
    "        #    if torch.is_tensor(image):\n",
    "        #       image = image.squeeze().numpy()\n",
    "        #    transformed = self.transform(image=image)\n",
    "        #    image = transformed['image'] \n",
    "     \n",
    "        # if not torch.is_tensor(image):\n",
    "        #     image = torch.from_numpy(image)\n",
    "        \n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 426 μs (started: 2025-03-06 20:12:41 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def create_sampler_with_weighted_sampler(labels):\n",
    "    class_counts = torch.bincount(labels)\n",
    "    weights = 1.0 / class_counts.float()\n",
    "    sample_weights = weights[labels]\n",
    "\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(labels),\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 811 μs (started: 2025-03-06 21:35:48 +02:00)\n"
     ]
    }
   ],
   "source": [
    "def create_train_val_loaders(train_images, train_labels, val_size=0.15, batch_size=batch_size, num_workers=num_workers, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    dataset_size = len(train_labels)\n",
    "    val_length = int(dataset_size * val_size)\n",
    "    train_length = dataset_size - val_length\n",
    "    \n",
    "    full_train_dataset = CarDataset(\n",
    "        train_images, \n",
    "        train_labels,\n",
    "    )\n",
    "    \n",
    "    train_subset, val_subset = random_split(\n",
    "        full_train_dataset, \n",
    "        [train_length, val_length],\n",
    "        generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "    \n",
    "    # train_subset.dataset.transform = train_transform \n",
    "    \n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        # sampler=create_sampler_with_weighted_sampler(train_subset.dataset.labels),\n",
    "        # num_workers=num_workers,\n",
    "        # persistent_workers=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        # num_workers=num_workers,\n",
    "        # persistent_workers=True,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Data Split Information\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total dataset size: {dataset_size}\")\n",
    "    print(f\"Training set size: {train_length}\")\n",
    "    print(f\"Validation set size: {val_length}\")\n",
    "    print(f\"Number of training batches: {len(train_loader)}\")\n",
    "    print(f\"Number of validation batches: {len(val_loader)}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Data Split Information\n",
      "==================================================\n",
      "Total dataset size: 45440\n",
      "Training set size: 38624\n",
      "Validation set size: 6816\n",
      "Number of training batches: 302\n",
      "Number of validation batches: 54\n",
      "==================================================\n",
      "\n",
      "time: 6.33 ms (started: 2025-03-06 21:35:53 +02:00)\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = create_train_val_loaders(train_images, train_labels, batch_size=128)\n",
    "\n",
    "test_dataset = CarDataset(test_images, test_labels)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Basic CNN Architecture\n",
    "In this experiment, we will:\n",
    "- Design a basic CNN architecture from scratch\n",
    "- Train the model on the prepared dataset\n",
    "- Evaluate the model performance\n",
    "- Analyze the results and identify areas for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Grayscale_CNN_exp_1_GAP(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "  (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc3): Linear(in_features=64, out_features=196, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62.8 ms (started: 2025-03-06 22:27:04 +02:00)\n"
     ]
    }
   ],
   "source": [
    "class Grayscale_CNN_exp_1_GAP(nn.Module):\n",
    "    def __init__(self, num_classes=196):\n",
    "        super(Grayscale_CNN_exp_1_GAP, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding='same')\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, padding='same')\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, padding='same')\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Global Average Pooling Layer\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))  # Output size of (1, 1)\n",
    "\n",
    "        # Final classification layer\n",
    "        self.fc3 = nn.Linear(64, num_classes)  # Input is now just the number of channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Apply Global Average Pooling\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten to [batch_size, 64]\n",
    "\n",
    "        # Classification\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "# Create an instance of the model\n",
    "grayscale_cnn_exp1_model = Grayscale_CNN_exp_1_GAP()\n",
    "grayscale_cnn_exp1_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/16], Loss: 1.8517, Validation Loss: 2.5449, Validation Accuracy: 37.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/16], Loss: 1.8079, Validation Loss: 2.8378, Validation Accuracy: 35.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/16], Loss: 1.7869, Validation Loss: 2.6461, Validation Accuracy: 36.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/16], Loss: 1.7555, Validation Loss: 2.5878, Validation Accuracy: 38.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/16], Loss: 1.7462, Validation Loss: 2.8090, Validation Accuracy: 33.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/16], Loss: 1.6986, Validation Loss: 2.6300, Validation Accuracy: 39.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/16], Loss: 1.6911, Validation Loss: 2.6631, Validation Accuracy: 38.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/16], Loss: 1.6748, Validation Loss: 2.5255, Validation Accuracy: 40.18%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/16], Loss: 1.6652, Validation Loss: 2.6350, Validation Accuracy: 37.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/16], Loss: 1.6521, Validation Loss: 2.5197, Validation Accuracy: 41.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/16], Loss: 1.6134, Validation Loss: 2.6249, Validation Accuracy: 38.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/16], Loss: 1.6105, Validation Loss: 2.5421, Validation Accuracy: 39.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/16], Loss: 1.5902, Validation Loss: 2.9341, Validation Accuracy: 37.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/16], Loss: 1.5651, Validation Loss: 2.7750, Validation Accuracy: 37.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/16], Loss: 1.5570, Validation Loss: 3.1475, Validation Accuracy: 31.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/16], Loss: 1.5333, Validation Loss: 2.7738, Validation Accuracy: 38.20%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2951\n",
      "F1 Score: 0.2893\n",
      "Precision: 0.3769\n",
      "Recall: 0.2951\n",
      "time: 4min 33s (started: 2025-03-06 22:39:24 +02:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoavgal/code/car-classification/.conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "epochs=15 #65 \n",
    "lr=0.01\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(grayscale_cnn_exp1_model.parameters(), lr)\n",
    "\n",
    "train_loss, val_loss, train_acc, val_acc = training_loop(\n",
    "    grayscale_cnn_exp1_model, optimizer, criterion, epochs, train_loader, val_loader, is_clip=True ,none_blocking=True)\n",
    "\n",
    "visualize_results(train_loss, val_loss, train_acc, val_acc)\n",
    "generate_classification_report(grayscale_cnn_exp1_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Transfer Learning Approach\n",
    "In this experiment, we will:\n",
    "- Utilize pre-trained models (e.g., ResNet, VGG, EfficientNet)\n",
    "- Fine-tune the models for our car classification task\n",
    "- Compare the performance with the basic CNN architecture\n",
    "- Analyze the benefits and limitations of transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: Advanced Techniques\n",
    "In this experiment, we will:\n",
    "- Implement advanced techniques such as data augmentation\n",
    "- Explore different optimization strategies\n",
    "- Experiment with ensemble methods\n",
    "- Analyze the impact of these techniques on model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model\n",
    "In this section, we will:\n",
    "- Save the best performing model\n",
    "- Document the model architecture and hyperparameters\n",
    "- Prepare the model for deployment or future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /Users/yoavgal/code/car-classification/CNN-notebook/./saved_models/Grayscale_CNN_exp_1_GAP\n",
      "time: 52.7 ms (started: 2025-03-06 22:48:14 +02:00)\n"
     ]
    }
   ],
   "source": [
    "model_filename = \"Grayscale_CNN_exp_1_GAP\"\n",
    "save_best_model(grayscale_cnn_exp1_model,model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model\n",
    "In this section, we will:\n",
    "- Evaluate the final model on the test dataset\n",
    "- Generate classification reports and confusion matrices\n",
    "- Visualize the model's predictions on sample images\n",
    "- Discuss the strengths and weaknesses of our approach"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
